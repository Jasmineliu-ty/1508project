{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB35cnMAPawy"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2xP_bVlO9Ad",
        "outputId": "781b6701-3d3d-4f8a-a7a0-f84b15eeb266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_rj8K2VPJO-"
      },
      "source": [
        "# finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVil688PVkr2"
      },
      "source": [
        "## nn struc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Geqsb-lO_LO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "from operator import itemgetter\n",
        "from heapq import nsmallest\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "class FilterPrunner:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.filter_ranks = {}\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.activations = []\n",
        "        self.gradients = []\n",
        "        self.grad_index = 0\n",
        "        self.activation_to_layer = {}\n",
        "\n",
        "        activation_index = 0\n",
        "        for layer, (name, module) in enumerate(self.model.features._modules.items()):\n",
        "            x = module(x)\n",
        "            if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
        "                x.register_hook(self.compute_rank)\n",
        "                self.activations.append(x)\n",
        "                self.activation_to_layer[activation_index] = layer\n",
        "                activation_index += 1\n",
        "\n",
        "        x = self.model.adaptive_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return self.model.classifier(x)\n",
        "\n",
        "    def compute_rank(self, grad):\n",
        "        activation_index = len(self.activations) - self.grad_index - 1\n",
        "        activation = self.activations[activation_index]\n",
        "\n",
        "        taylor = activation * grad\n",
        "        # Get the average value for every filter,\n",
        "        # accross all the other dimensions\n",
        "        taylor = taylor.mean(dim=(0, 2, 3)).data\n",
        "\n",
        "\n",
        "        if activation_index not in self.filter_ranks:\n",
        "            self.filter_ranks[activation_index] = \\\n",
        "                torch.FloatTensor(activation.size(1)).zero_()\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "              self.filter_ranks[activation_index] = self.filter_ranks[activation_index].cuda()\n",
        "            else:\n",
        "              print(\"CUDA is not available. Running on CPU.\")\n",
        "\n",
        "        self.filter_ranks[activation_index] += taylor\n",
        "        self.grad_index += 1\n",
        "\n",
        "    def lowest_ranking_filters(self, num):\n",
        "        data = []\n",
        "        for i in sorted(self.filter_ranks.keys()):\n",
        "            for j in range(self.filter_ranks[i].size(0)):\n",
        "                data.append((self.activation_to_layer[i], j, self.filter_ranks[i][j]))\n",
        "\n",
        "        return nsmallest(num, data, itemgetter(2))\n",
        "\n",
        "    def normalize_ranks_per_layer(self):\n",
        "        for i in self.filter_ranks:\n",
        "            v = torch.abs(self.filter_ranks[i])\n",
        "            v = v / torch.sqrt(torch.sum(v * v))\n",
        "            self.filter_ranks[i] = v.cpu()\n",
        "\n",
        "    def get_prunning_plan(self, num_filters_to_prune):\n",
        "        filters_to_prune = self.lowest_ranking_filters(num_filters_to_prune)\n",
        "\n",
        "        # After each of the k filters are prunned,\n",
        "        # the filter index of the next filters change since the model is smaller.\n",
        "        filters_to_prune_per_layer = {}\n",
        "        for (l, f, _) in filters_to_prune:\n",
        "            if l not in filters_to_prune_per_layer:\n",
        "                filters_to_prune_per_layer[l] = []\n",
        "            filters_to_prune_per_layer[l].append(f)\n",
        "\n",
        "        for l in filters_to_prune_per_layer:\n",
        "            filters_to_prune_per_layer[l] = sorted(filters_to_prune_per_layer[l])\n",
        "            for i in range(len(filters_to_prune_per_layer[l])):\n",
        "                filters_to_prune_per_layer[l][i] = filters_to_prune_per_layer[l][i] - i\n",
        "\n",
        "        filters_to_prune = []\n",
        "        for l in filters_to_prune_per_layer:\n",
        "            for i in filters_to_prune_per_layer[l]:\n",
        "                filters_to_prune.append((l, i))\n",
        "\n",
        "        return filters_to_prune\n",
        "\n",
        "class PrunningFineTuner_VGG16:\n",
        "    def __init__(self, trainloader, testloader, model):\n",
        "        self.train_data_loader = trainloader\n",
        "        self.test_data_loader = testloader\n",
        "        self.model = model\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "        self.prunner = FilterPrunner(self.model)\n",
        "        self.model.train()\n",
        "\n",
        "    def test(self):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, (batch, label) in enumerate(self.test_data_loader):\n",
        "            if torch.cuda.is_available():\n",
        "              batch = batch.cuda()\n",
        "            else:\n",
        "             print(\"CUDA is not available. Running on CPU.\")\n",
        "\n",
        "            output = model(Variable(batch))\n",
        "            pred = output.data.max(1)[1]\n",
        "            correct += pred.cpu().eq(label).sum()\n",
        "            total += label.size(0)\n",
        "\n",
        "        print(\"Accuracy :\", float(correct) / total)\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "    def train(self, optimizer = None, epoches=10):\n",
        "        if optimizer is None:\n",
        "            optimizer = optim.SGD(model.classifier.parameters(), lr=0.0001, momentum=0.9)\n",
        "\n",
        "        for i in range(epoches):\n",
        "            print(\"Epoch: \", i)\n",
        "            self.train_epoch(optimizer)\n",
        "            self.test()\n",
        "        print(\"Finished fine tuning.\")\n",
        "\n",
        "\n",
        "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            batch = batch.cuda()\n",
        "            label = label.cuda()\n",
        "        else:\n",
        "          print(\"CUDA is not available. Running on CPU.\")\n",
        "\n",
        "\n",
        "        self.model.zero_grad()\n",
        "        input = Variable(batch)\n",
        "\n",
        "        if rank_filters:\n",
        "            output = self.prunner.forward(input)\n",
        "            self.criterion(output, Variable(label)).backward()\n",
        "        else:\n",
        "            model_output = self.model(input)\n",
        "            #print(\"size\")\n",
        "            #print(model_output.size())\n",
        "            #print(label.size())\n",
        "            var_label = Variable(label)\n",
        "           # print(var_label.size())\n",
        "            loss = self.criterion(model_output, var_label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
        "        for i, (batch, label) in enumerate(self.train_data_loader):\n",
        "            self.train_batch(optimizer, batch, label, rank_filters)\n",
        "\n",
        "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
        "        self.prunner.reset()\n",
        "        self.train_epoch(rank_filters = True)\n",
        "        self.prunner.normalize_ranks_per_layer()\n",
        "        return self.prunner.get_prunning_plan(num_filters_to_prune)\n",
        "\n",
        "    def total_num_filters(self):\n",
        "        filters = 0\n",
        "        for name, module in self.model.features._modules.items():\n",
        "            if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
        "                filters = filters + module.out_channels\n",
        "        return filters\n",
        "\n",
        "    def prune(self):\n",
        "        #Get the accuracy before prunning\n",
        "        self.test()\n",
        "        self.model.train()\n",
        "\n",
        "        #Make sure all the layers are trainable\n",
        "        for param in self.model.features.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        number_of_filters = self.total_num_filters()\n",
        "        num_filters_to_prune_per_iteration = 512\n",
        "        iterations = int(float(number_of_filters) / num_filters_to_prune_per_iteration)\n",
        "\n",
        "        iterations = int(iterations * 2.0 / 3)\n",
        "\n",
        "        print(\"Number of prunning iterations to reduce 67% filters\", iterations)\n",
        "\n",
        "        for _ in range(iterations):\n",
        "            print(\"Ranking filters.. \")\n",
        "            prune_targets = self.get_candidates_to_prune(num_filters_to_prune_per_iteration)\n",
        "            layers_prunned = {}\n",
        "            for layer_index, filter_index in prune_targets:\n",
        "                if layer_index not in layers_prunned:\n",
        "                    layers_prunned[layer_index] = 0\n",
        "                layers_prunned[layer_index] = layers_prunned[layer_index] + 1\n",
        "\n",
        "            print(\"Layers that will be prunned\", layers_prunned)\n",
        "            print(\"Prunning filters.. \")\n",
        "            model = self.model.cpu()\n",
        "            for layer_index, filter_index in prune_targets:\n",
        "                if torch.cuda.is_available():\n",
        "                  use_cuda= True\n",
        "                else:\n",
        "                  print(\"CUDA is not available. Running on CPU.\")\n",
        "                model = prune_vgg16_conv_layer(model, layer_index, filter_index, use_cuda=use_cuda)\n",
        "\n",
        "            self.model = model\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "              self.model = self.model.cuda()\n",
        "            else:\n",
        "             print(\"CUDA is not available. Running on CPU.\")\n",
        "\n",
        "            message = str(100*float(self.total_num_filters()) / number_of_filters) + \"%\"\n",
        "            print(\"Filters prunned\", str(message))\n",
        "            self.test()\n",
        "            print(\"Fine tuning to recover from prunning iteration.\")\n",
        "            optimizer = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
        "            self.train(optimizer, epoches = 10)\n",
        "\n",
        "\n",
        "        print(\"Finished. Going to fine tune the model a bit more\")\n",
        "        self.train(optimizer, epoches=15)\n",
        "        torch.save(model.state_dict(), \"model_prunned\")\n",
        "\n",
        "# class ModifiedVGG16Model(torch.nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(ModifiedVGG16Model, self).__init__()\n",
        "\n",
        "#         model = models.vgg16(pretrained=True)\n",
        "#         self.features = model.features\n",
        "\n",
        "#         for param in self.features.parameters():\n",
        "#             param.requires_grad = False\n",
        "\n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.Dropout(),\n",
        "#             nn.Linear(25088, 4096),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Dropout(),\n",
        "#             nn.Linear(4096, 4096),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Linear(4096, 10))    # nn.Linear(4096, 2)) -> nn.Linear(4096, 10))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.features(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         print(\"xsize\")\n",
        "#         print(x.size())\n",
        "#         x = self.classifier(x)\n",
        "#         return x\n",
        "class ModifiedVGG16Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModifiedVGG16Model, self).__init__()\n",
        "\n",
        "        model = models.vgg16(pretrained=True)\n",
        "        self.features = model.features\n",
        "\n",
        "        # Freeze the feature extractor\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Add an adaptive pooling layer to ensure a consistent size\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))  # Ensure output is 512x7x7\n",
        "\n",
        "        # Define the classifier with correct input size\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512 * 7 * 7, 4096),  # Flattened size of feature map\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 10)  # CIFAR-10 has 10 classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.adaptive_pool(x)  # Add adaptive pooling\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.classifier(x)     # Pass through the classifier\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8PO5Sn3Pfte"
      },
      "source": [
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTnjZmFUPntj",
        "outputId": "74078948-7424-4b2c-8ef1-76e69b446638"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Accuracy : 0.4949\n",
            "Epoch:  1\n",
            "Accuracy : 0.5368\n",
            "Epoch:  2\n",
            "Accuracy : 0.5535\n",
            "Epoch:  3\n",
            "Accuracy : 0.556\n",
            "Epoch:  4\n",
            "Accuracy : 0.5698\n",
            "Epoch:  5\n",
            "Accuracy : 0.5778\n",
            "Epoch:  6\n",
            "Accuracy : 0.5815\n",
            "Epoch:  7\n",
            "Accuracy : 0.5791\n",
            "Epoch:  8\n",
            "Accuracy : 0.5843\n",
            "Epoch:  9\n",
            "Accuracy : 0.588\n",
            "Finished fine tuning.\n"
          ]
        }
      ],
      "source": [
        "# def get_args():\n",
        "#     parser = argparse.ArgumentParser()\n",
        "#     parser.add_argument(\"--train\", dest=\"train\", action=\"store_true\")\n",
        "#     parser.add_argument(\"--prune\", dest=\"prune\", action=\"store_true\")\n",
        "#     parser.add_argument(\"--train_path\", type = str, default = \"train\")\n",
        "#     parser.add_argument(\"--test_path\", type = str, default = \"test\")\n",
        "#     parser.add_argument('--use-cuda', action='store_true', default=False, help='Use NVIDIA GPU acceleration')\n",
        "#     parser.set_defaults(train=False)\n",
        "#     parser.set_defaults(prune=False)\n",
        "#     args = parser.parse_args()\n",
        "#     args.use_cuda = args.use_cuda and torch.cuda.is_available()\n",
        "\n",
        "#     return args\n",
        "train = True\n",
        "prune = False\n",
        "if __name__ == '__main__':\n",
        "    # args = get_args()\n",
        "\n",
        "    if train:\n",
        "        model = ModifiedVGG16Model()\n",
        "    elif prune:\n",
        "        model = torch.load(\"model\", map_location=lambda storage, loc: storage)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "    else:\n",
        "        print(\"CUDA is not available. Running on CPU.\")\n",
        "\n",
        "    fine_tuner = PrunningFineTuner_VGG16(trainloader, testloader, model)\n",
        "\n",
        "    if train:\n",
        "        fine_tuner.train(epoches=10)\n",
        "        torch.save(model, \"model\")\n",
        "\n",
        "    elif prune:\n",
        "        fine_tuner.prune()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZPkISBdPsfg"
      },
      "source": [
        "# prune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2GBngiWPy4N"
      },
      "source": [
        "## body part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ4-IvrYPup1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def replace_layers(model, i, indexes, layers):\n",
        "    if i in indexes:\n",
        "        return layers[indexes.index(i)]\n",
        "    return model[i]\n",
        "\n",
        "def prune_vgg16_conv_layer(model, layer_index, filter_index, use_cuda=False):\n",
        "    _, conv = list(model.features._modules.items())[layer_index]\n",
        "    next_conv = None\n",
        "    offset = 1\n",
        "\n",
        "    while layer_index + offset <  len(model.features._modules.items()):\n",
        "        res =  list(model.features._modules.items())[layer_index+offset]\n",
        "        if isinstance(res[1], torch.nn.modules.conv.Conv2d):\n",
        "            next_name, next_conv = res\n",
        "            break\n",
        "        offset = offset + 1\n",
        "\n",
        "    new_conv = \\\n",
        "        torch.nn.Conv2d(in_channels = conv.in_channels, \\\n",
        "            out_channels = conv.out_channels - 1,\n",
        "            kernel_size = conv.kernel_size, \\\n",
        "            stride = conv.stride,\n",
        "            padding = conv.padding,\n",
        "            dilation = conv.dilation,\n",
        "            groups = conv.groups,\n",
        "            bias = (conv.bias is not None))\n",
        "\n",
        "    old_weights = conv.weight.data.cpu().numpy()\n",
        "    new_weights = new_conv.weight.data.cpu().numpy()\n",
        "\n",
        "    new_weights[: filter_index, :, :, :] = old_weights[: filter_index, :, :, :]\n",
        "    new_weights[filter_index : , :, :, :] = old_weights[filter_index + 1 :, :, :, :]\n",
        "    new_conv.weight.data = torch.from_numpy(new_weights)\n",
        "    if use_cuda:\n",
        "        new_conv.weight.data = new_conv.weight.data.cuda()\n",
        "\n",
        "    bias_numpy = conv.bias.data.cpu().numpy()\n",
        "\n",
        "    bias = np.zeros(shape = (bias_numpy.shape[0] - 1), dtype = np.float32)\n",
        "    bias[:filter_index] = bias_numpy[:filter_index]\n",
        "    bias[filter_index : ] = bias_numpy[filter_index + 1 :]\n",
        "    new_conv.bias.data = torch.from_numpy(bias)\n",
        "    if use_cuda:\n",
        "        new_conv.bias.data = new_conv.bias.data.cuda()\n",
        "\n",
        "    if not next_conv is None:\n",
        "        next_new_conv = \\\n",
        "            torch.nn.Conv2d(in_channels = next_conv.in_channels - 1,\\\n",
        "                out_channels =  next_conv.out_channels, \\\n",
        "                kernel_size = next_conv.kernel_size, \\\n",
        "                stride = next_conv.stride,\n",
        "                padding = next_conv.padding,\n",
        "                dilation = next_conv.dilation,\n",
        "                groups = next_conv.groups,\n",
        "                bias = (next_conv.bias is not None))\n",
        "\n",
        "        old_weights = next_conv.weight.data.cpu().numpy()\n",
        "        new_weights = next_new_conv.weight.data.cpu().numpy()\n",
        "\n",
        "        new_weights[:, : filter_index, :, :] = old_weights[:, : filter_index, :, :]\n",
        "        new_weights[:, filter_index : , :, :] = old_weights[:, filter_index + 1 :, :, :]\n",
        "        next_new_conv.weight.data = torch.from_numpy(new_weights)\n",
        "        if use_cuda:\n",
        "            next_new_conv.weight.data = next_new_conv.weight.data.cuda()\n",
        "\n",
        "        next_new_conv.bias.data = next_conv.bias.data\n",
        "\n",
        "    if not next_conv is None:\n",
        "        features = torch.nn.Sequential(\n",
        "                *(replace_layers(model.features, i, [layer_index, layer_index+offset], \\\n",
        "                    [new_conv, next_new_conv]) for i, _ in enumerate(model.features)))\n",
        "        del model.features\n",
        "        del conv\n",
        "\n",
        "        model.features = features\n",
        "\n",
        "    else:\n",
        "        #Prunning the last conv layer. This affects the first linear layer of the classifier.\n",
        "        model.features = torch.nn.Sequential(\n",
        "                *(replace_layers(model.features, i, [layer_index], \\\n",
        "                    [new_conv]) for i, _ in enumerate(model.features)))\n",
        "        layer_index = 0\n",
        "        old_linear_layer = None\n",
        "        for _, module in model.classifier._modules.items():\n",
        "            if isinstance(module, torch.nn.Linear):\n",
        "                old_linear_layer = module\n",
        "                break\n",
        "            layer_index = layer_index  + 1\n",
        "\n",
        "        if old_linear_layer is None:\n",
        "            raise BaseException(\"No linear laye found in classifier\")\n",
        "        params_per_input_channel = old_linear_layer.in_features // conv.out_channels\n",
        "\n",
        "        new_linear_layer = \\\n",
        "            torch.nn.Linear(old_linear_layer.in_features - params_per_input_channel,\n",
        "                old_linear_layer.out_features)\n",
        "\n",
        "        old_weights = old_linear_layer.weight.data.cpu().numpy()\n",
        "        new_weights = new_linear_layer.weight.data.cpu().numpy()\n",
        "\n",
        "        new_weights[:, : filter_index * params_per_input_channel] = \\\n",
        "            old_weights[:, : filter_index * params_per_input_channel]\n",
        "        new_weights[:, filter_index * params_per_input_channel :] = \\\n",
        "            old_weights[:, (filter_index + 1) * params_per_input_channel :]\n",
        "\n",
        "        new_linear_layer.bias.data = old_linear_layer.bias.data\n",
        "\n",
        "        new_linear_layer.weight.data = torch.from_numpy(new_weights)\n",
        "        if use_cuda:\n",
        "            new_linear_layer.weight.data = new_linear_layer.weight.data.cuda()\n",
        "\n",
        "        classifier = torch.nn.Sequential(\n",
        "            *(replace_layers(model.classifier, i, [layer_index], \\\n",
        "                [new_linear_layer]) for i, _ in enumerate(model.classifier)))\n",
        "\n",
        "        del model.classifier\n",
        "        del next_conv\n",
        "        del conv\n",
        "        model.classifier = classifier\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB-TLb1_P4C_"
      },
      "source": [
        "## run code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feO3EDdTP3Nl",
        "outputId": "51d0e034-6b43-4a2e-9f92-ce2ed9f787e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The prunning took 1.2256815433502197\n",
            "205313\n",
            "138152231\n",
            "138357544\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    model = models.vgg16(pretrained=True)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    model.train()\n",
        "\n",
        "    t0 = time.time()\n",
        "    model = prune_vgg16_conv_layer(model, 28, 10)\n",
        "    print(\"The prunning took\", time.time() - t0)\n",
        "    remaining_params = sum(p.nonzero().size(0) for p in model.parameters())\n",
        "    pruned_params = total_params - remaining_params\n",
        "    print(pruned_params)\n",
        "    print(remaining_params)\n",
        "    print(total_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCTheWeGY3qd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}